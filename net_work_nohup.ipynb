{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os \n","from itertools import product\n","from tqdm.notebook import tqdm\n","import statsmodels.api as sm\n","from multiprocessing import Pool\n","import matplotlib.pyplot as plt\n","import datetime\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout, Embedding\n","# import keras\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# all_stock_result = {}\n","# for code_path in os.listdir('/code/task4-imbalance/train_result'):\n","#     all_stock_result[code_path[18:-4]] = pd.read_pickle(os.path.join('/code/task4-imbalance/train_result', code_path))\n","\n","all_stock_result = pd.read_pickle('/code/task4-imbalance/all_stock_result.pkl')\n","\n","x_train_split = [x[0] for x in list(all_stock_result.values())]\n","x_train_all = np.concatenate(x_train_split)\n","\n","y_train_split = [y[2] for y in list(all_stock_result.values())]\n","y_train_all = np.concatenate(y_train_split)\n","\n","x_test_split = [x[3] for x in list(all_stock_result.values())]\n","x_test_all = np.concatenate(x_test_split)\n","\n","y_test_split = [y[5] for y in list(all_stock_result.values())]\n","y_test_all = np.concatenate(y_test_split)\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# pd.to_pickle(all_stock_result, 'all_stock_result.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 对每个sample的最后一个ylabel进行预测\n","model1 = Sequential()\n","\n","# model1.add(Dense(32))  # 维度为 32 的全连接层\n","timesteps = x_train_all.shape[1]\n","data_dim = x_train_all.shape[2]-3\n","# data_dim = 5\n","\n","model1.add(LSTM(128, return_sequences=True,\n","               input_shape=(timesteps, data_dim)))  # 返回维度为 128 的向量序列\n","\n","model1.add(Dropout(0.5))    # dropout 0.5\n","\n","model1.add(LSTM(128, return_sequences=False))  # 返回维度为 128 的向量序列\n","\n","model1.add(Dense(32))  # 维度为 32 的全连接层\n","model1.add(Dense(3, activation='softmax'))    # softmax 后的最终结果\n","\n","\n","# model1.add(LSTM(512, return_sequences=True))  # 返回维度为 1024 的向量序列\n","# model1.add(LSTM(512//2, return_sequences=True))  # 返回维度为 512 的向量序列\n","# model1.add(LSTM(256//2, return_sequences=False))  # 返回维度为 256 的向量序列\n","\n","# model1.add(Dense(128))  # 维度为 128 的全连接层\n","# model1.add(Dense(6))  # 维度为 6 的全连接层\n","# model1.add(Dense(3, activation='softmax'))    # softmax 后的最终结果\n","\n","model1_opt = optimizers.Adam(lr = 0.0005)\n","model1.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","early_stop = EarlyStopping(min_delta=0.002,patience=2)   \n","\n","# 对y序列进行预测 \n","his = model1.fit(x_train_all[:,:,:-3], y_train_all,          \n","          batch_size=1024, epochs=30,\n","          validation_data=(x_test_all[:,:,:-3], y_test_all),\n","          callbacks=[early_stop])\n","\n","model1.save('/code/task4-imbalance/models/model_l_bp_l_2d_allstock.h5')       # \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(16,20))\n","ax1 = plt.subplot(2,1,1)\n","ax1.plot(his.history['loss'],label='train_loss')\n","ax1.plot(his.history['val_loss'], label='val_loss')\n","ax1.set_title('loss',fontdict={'size':16})\n","\n","plt.legend(prop = {'size':16})\n","plt.tick_params(labelsize=15)\n","plt.xticks(range(0,len(his.history['val_loss'])))\n","plt.xlabel('epoch',size=16)\n","\n","ax2 = plt.subplot(2,1,2)\n","ax2.plot(his.history['accuracy'],label='train_acc')\n","ax2.plot(his.history['val_accuracy'], label='val_acc')\n","plt.legend(prop = {'size':16})\n","plt.tick_params(labelsize=15)\n","plt.xticks(range(0,len(his.history['val_loss'])))\n","plt.xlabel('epoch',size=16)\n","ax2.set_title('accuracy',fontdict={'size':16})\n","\n","# plt.set_ticks_position('top')\n","# plt.subplots_adjust(hspace=0.1)\n","plt.savefig('loss_allstock.png' , bbox_inches='tight')\n","\n","\n","df_result = pd.concat([pd.Series(x) for x in his.history.values()],axis=1)\n","df_result.columns = ['train_loss','train_acc','val_loss','val_acc']\n","df_result.index.names=['epoch']\n","df_result.iloc[-1:,:].round(4)\n","\n","best_result = pd.DataFrame([[np.argmax(df_result.train_acc),df_result.train_loss.min(), df_result.train_acc.max(),np.argmax(df_result.val_acc),df_result.val_loss.min(), df_result.val_acc.max()]],columns=['best_train_epoch','train_loss','train_acc','best_val_epoch','val_loss','val_acc']).round(4)\n","\n","pd.to_csv(best_result, 'best_result_all_stock.csv')\n","\n","# his.history\n","\n","\n"]}],"metadata":{"interpreter":{"hash":"40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"},"kernelspec":{"display_name":"Python 3.7.6 64-bit ('base': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
